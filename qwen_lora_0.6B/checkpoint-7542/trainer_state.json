{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 7542,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.039785160135269546,
      "grad_norm": 2.8088185787200928,
      "learning_rate": 1.973747016706444e-05,
      "loss": 3.2339,
      "step": 100
    },
    {
      "epoch": 0.07957032027053909,
      "grad_norm": 1.8473814725875854,
      "learning_rate": 1.947228851763458e-05,
      "loss": 1.9499,
      "step": 200
    },
    {
      "epoch": 0.11935548040580864,
      "grad_norm": 5.9708356857299805,
      "learning_rate": 1.920710686820472e-05,
      "loss": 1.8302,
      "step": 300
    },
    {
      "epoch": 0.15914064054107818,
      "grad_norm": 2.072593927383423,
      "learning_rate": 1.8941925218774862e-05,
      "loss": 1.7891,
      "step": 400
    },
    {
      "epoch": 0.1989258006763477,
      "grad_norm": 4.230320453643799,
      "learning_rate": 1.8676743569345004e-05,
      "loss": 1.7413,
      "step": 500
    },
    {
      "epoch": 0.23871096081161727,
      "grad_norm": 3.7124722003936768,
      "learning_rate": 1.8411561919915143e-05,
      "loss": 1.6832,
      "step": 600
    },
    {
      "epoch": 0.2784961209468868,
      "grad_norm": 6.708687782287598,
      "learning_rate": 1.8146380270485286e-05,
      "loss": 1.7096,
      "step": 700
    },
    {
      "epoch": 0.31828128108215636,
      "grad_norm": 4.387475967407227,
      "learning_rate": 1.7881198621055425e-05,
      "loss": 1.6378,
      "step": 800
    },
    {
      "epoch": 0.3580664412174259,
      "grad_norm": 5.2499098777771,
      "learning_rate": 1.7616016971625564e-05,
      "loss": 1.6524,
      "step": 900
    },
    {
      "epoch": 0.3978516013526954,
      "grad_norm": 2.5200400352478027,
      "learning_rate": 1.7350835322195706e-05,
      "loss": 1.6224,
      "step": 1000
    },
    {
      "epoch": 0.437636761487965,
      "grad_norm": 3.8102102279663086,
      "learning_rate": 1.7085653672765845e-05,
      "loss": 1.6261,
      "step": 1100
    },
    {
      "epoch": 0.47742192162323455,
      "grad_norm": 3.2949507236480713,
      "learning_rate": 1.6820472023335987e-05,
      "loss": 1.5718,
      "step": 1200
    },
    {
      "epoch": 0.517207081758504,
      "grad_norm": 5.569694995880127,
      "learning_rate": 1.6555290373906126e-05,
      "loss": 1.5222,
      "step": 1300
    },
    {
      "epoch": 0.5569922418937736,
      "grad_norm": 2.129417896270752,
      "learning_rate": 1.629010872447627e-05,
      "loss": 1.5982,
      "step": 1400
    },
    {
      "epoch": 0.5967774020290432,
      "grad_norm": 6.055895805358887,
      "learning_rate": 1.6024927075046408e-05,
      "loss": 1.5674,
      "step": 1500
    },
    {
      "epoch": 0.6365625621643127,
      "grad_norm": 10.287464141845703,
      "learning_rate": 1.5759745425616547e-05,
      "loss": 1.5397,
      "step": 1600
    },
    {
      "epoch": 0.6763477222995823,
      "grad_norm": 6.9110517501831055,
      "learning_rate": 1.549456377618669e-05,
      "loss": 1.5333,
      "step": 1700
    },
    {
      "epoch": 0.7161328824348518,
      "grad_norm": 5.878293514251709,
      "learning_rate": 1.5229382126756828e-05,
      "loss": 1.5003,
      "step": 1800
    },
    {
      "epoch": 0.7559180425701213,
      "grad_norm": 10.406352996826172,
      "learning_rate": 1.496420047732697e-05,
      "loss": 1.5363,
      "step": 1900
    },
    {
      "epoch": 0.7957032027053909,
      "grad_norm": 6.467503547668457,
      "learning_rate": 1.4699018827897111e-05,
      "loss": 1.5123,
      "step": 2000
    },
    {
      "epoch": 0.8354883628406604,
      "grad_norm": 8.858511924743652,
      "learning_rate": 1.4433837178467252e-05,
      "loss": 1.4702,
      "step": 2100
    },
    {
      "epoch": 0.87527352297593,
      "grad_norm": 6.877720832824707,
      "learning_rate": 1.4168655529037391e-05,
      "loss": 1.5136,
      "step": 2200
    },
    {
      "epoch": 0.9150586831111995,
      "grad_norm": 6.278656482696533,
      "learning_rate": 1.3903473879607532e-05,
      "loss": 1.4678,
      "step": 2300
    },
    {
      "epoch": 0.9548438432464691,
      "grad_norm": 8.610166549682617,
      "learning_rate": 1.3638292230177672e-05,
      "loss": 1.4524,
      "step": 2400
    },
    {
      "epoch": 0.9946290033817387,
      "grad_norm": 8.57265567779541,
      "learning_rate": 1.3373110580747813e-05,
      "loss": 1.4903,
      "step": 2500
    },
    {
      "epoch": 1.0342152377163318,
      "grad_norm": 4.434014797210693,
      "learning_rate": 1.3107928931317955e-05,
      "loss": 1.4886,
      "step": 2600
    },
    {
      "epoch": 1.0740003978516013,
      "grad_norm": 7.556233882904053,
      "learning_rate": 1.2842747281888094e-05,
      "loss": 1.5064,
      "step": 2700
    },
    {
      "epoch": 1.113785557986871,
      "grad_norm": 9.641255378723145,
      "learning_rate": 1.2577565632458235e-05,
      "loss": 1.4152,
      "step": 2800
    },
    {
      "epoch": 1.1535707181221404,
      "grad_norm": 4.648369789123535,
      "learning_rate": 1.2312383983028376e-05,
      "loss": 1.4782,
      "step": 2900
    },
    {
      "epoch": 1.19335587825741,
      "grad_norm": 3.744987726211548,
      "learning_rate": 1.2047202333598516e-05,
      "loss": 1.4174,
      "step": 3000
    },
    {
      "epoch": 1.2331410383926795,
      "grad_norm": 8.662906646728516,
      "learning_rate": 1.1782020684168655e-05,
      "loss": 1.4862,
      "step": 3100
    },
    {
      "epoch": 1.2729261985279492,
      "grad_norm": 6.723379611968994,
      "learning_rate": 1.1516839034738796e-05,
      "loss": 1.4589,
      "step": 3200
    },
    {
      "epoch": 1.3127113586632186,
      "grad_norm": 7.509674549102783,
      "learning_rate": 1.1251657385308938e-05,
      "loss": 1.445,
      "step": 3300
    },
    {
      "epoch": 1.352496518798488,
      "grad_norm": 11.253674507141113,
      "learning_rate": 1.0986475735879079e-05,
      "loss": 1.4405,
      "step": 3400
    },
    {
      "epoch": 1.3922816789337578,
      "grad_norm": 14.101693153381348,
      "learning_rate": 1.0721294086449218e-05,
      "loss": 1.404,
      "step": 3500
    },
    {
      "epoch": 1.4320668390690272,
      "grad_norm": 5.916496753692627,
      "learning_rate": 1.0456112437019359e-05,
      "loss": 1.4243,
      "step": 3600
    },
    {
      "epoch": 1.4718519992042969,
      "grad_norm": 11.662294387817383,
      "learning_rate": 1.01909307875895e-05,
      "loss": 1.4641,
      "step": 3700
    },
    {
      "epoch": 1.5116371593395663,
      "grad_norm": 6.882638454437256,
      "learning_rate": 9.92574913815964e-06,
      "loss": 1.4341,
      "step": 3800
    },
    {
      "epoch": 1.551422319474836,
      "grad_norm": 10.177321434020996,
      "learning_rate": 9.66056748872978e-06,
      "loss": 1.4379,
      "step": 3900
    },
    {
      "epoch": 1.5912074796101054,
      "grad_norm": 9.262444496154785,
      "learning_rate": 9.395385839299922e-06,
      "loss": 1.4294,
      "step": 4000
    },
    {
      "epoch": 1.630992639745375,
      "grad_norm": 9.240220069885254,
      "learning_rate": 9.130204189870062e-06,
      "loss": 1.3807,
      "step": 4100
    },
    {
      "epoch": 1.6707777998806446,
      "grad_norm": 8.633049964904785,
      "learning_rate": 8.865022540440203e-06,
      "loss": 1.4456,
      "step": 4200
    },
    {
      "epoch": 1.710562960015914,
      "grad_norm": 6.23712158203125,
      "learning_rate": 8.599840891010342e-06,
      "loss": 1.4071,
      "step": 4300
    },
    {
      "epoch": 1.7503481201511835,
      "grad_norm": 9.568897247314453,
      "learning_rate": 8.334659241580483e-06,
      "loss": 1.4051,
      "step": 4400
    },
    {
      "epoch": 1.7901332802864531,
      "grad_norm": 10.572863578796387,
      "learning_rate": 8.069477592150625e-06,
      "loss": 1.4217,
      "step": 4500
    },
    {
      "epoch": 1.8299184404217228,
      "grad_norm": 10.212421417236328,
      "learning_rate": 7.804295942720764e-06,
      "loss": 1.4828,
      "step": 4600
    },
    {
      "epoch": 1.8697036005569923,
      "grad_norm": 10.351958274841309,
      "learning_rate": 7.539114293290905e-06,
      "loss": 1.3762,
      "step": 4700
    },
    {
      "epoch": 1.9094887606922617,
      "grad_norm": 6.725625514984131,
      "learning_rate": 7.273932643861046e-06,
      "loss": 1.3909,
      "step": 4800
    },
    {
      "epoch": 1.9492739208275314,
      "grad_norm": 5.865181922912598,
      "learning_rate": 7.008750994431186e-06,
      "loss": 1.3753,
      "step": 4900
    },
    {
      "epoch": 1.989059080962801,
      "grad_norm": 13.084776878356934,
      "learning_rate": 6.743569345001326e-06,
      "loss": 1.3659,
      "step": 5000
    },
    {
      "epoch": 2.028645315297394,
      "grad_norm": 8.891132354736328,
      "learning_rate": 6.478387695571467e-06,
      "loss": 1.365,
      "step": 5100
    },
    {
      "epoch": 2.0684304754326637,
      "grad_norm": 4.979772567749023,
      "learning_rate": 6.213206046141608e-06,
      "loss": 1.4234,
      "step": 5200
    },
    {
      "epoch": 2.1082156355679333,
      "grad_norm": 6.439319610595703,
      "learning_rate": 5.948024396711748e-06,
      "loss": 1.3698,
      "step": 5300
    },
    {
      "epoch": 2.1480007957032026,
      "grad_norm": 16.440793991088867,
      "learning_rate": 5.6828427472818885e-06,
      "loss": 1.4298,
      "step": 5400
    },
    {
      "epoch": 2.1877859558384722,
      "grad_norm": 15.280728340148926,
      "learning_rate": 5.417661097852029e-06,
      "loss": 1.3622,
      "step": 5500
    },
    {
      "epoch": 2.227571115973742,
      "grad_norm": 25.559669494628906,
      "learning_rate": 5.15247944842217e-06,
      "loss": 1.4368,
      "step": 5600
    },
    {
      "epoch": 2.2673562761090116,
      "grad_norm": 11.18529224395752,
      "learning_rate": 4.887297798992311e-06,
      "loss": 1.3399,
      "step": 5700
    },
    {
      "epoch": 2.307141436244281,
      "grad_norm": 4.546494483947754,
      "learning_rate": 4.62211614956245e-06,
      "loss": 1.3508,
      "step": 5800
    },
    {
      "epoch": 2.3469265963795505,
      "grad_norm": 5.957576751708984,
      "learning_rate": 4.356934500132591e-06,
      "loss": 1.3623,
      "step": 5900
    },
    {
      "epoch": 2.38671175651482,
      "grad_norm": 15.253531455993652,
      "learning_rate": 4.091752850702732e-06,
      "loss": 1.3041,
      "step": 6000
    },
    {
      "epoch": 2.4264969166500894,
      "grad_norm": 20.089256286621094,
      "learning_rate": 3.8265712012728725e-06,
      "loss": 1.3443,
      "step": 6100
    },
    {
      "epoch": 2.466282076785359,
      "grad_norm": 17.951496124267578,
      "learning_rate": 3.5613895518430123e-06,
      "loss": 1.2258,
      "step": 6200
    },
    {
      "epoch": 2.5060672369206287,
      "grad_norm": 8.945724487304688,
      "learning_rate": 3.2962079024131534e-06,
      "loss": 1.2919,
      "step": 6300
    },
    {
      "epoch": 2.5458523970558984,
      "grad_norm": 18.595123291015625,
      "learning_rate": 3.031026252983294e-06,
      "loss": 1.3816,
      "step": 6400
    },
    {
      "epoch": 2.5856375571911676,
      "grad_norm": 32.43061447143555,
      "learning_rate": 2.7658446035534344e-06,
      "loss": 1.4071,
      "step": 6500
    },
    {
      "epoch": 2.6254227173264373,
      "grad_norm": 7.608304023742676,
      "learning_rate": 2.500662954123575e-06,
      "loss": 1.3247,
      "step": 6600
    },
    {
      "epoch": 2.6652078774617065,
      "grad_norm": 34.64228057861328,
      "learning_rate": 2.2354813046937153e-06,
      "loss": 1.4319,
      "step": 6700
    },
    {
      "epoch": 2.704993037596976,
      "grad_norm": 15.764800071716309,
      "learning_rate": 1.970299655263856e-06,
      "loss": 1.3489,
      "step": 6800
    },
    {
      "epoch": 2.744778197732246,
      "grad_norm": 10.50950813293457,
      "learning_rate": 1.7051180058339964e-06,
      "loss": 1.407,
      "step": 6900
    },
    {
      "epoch": 2.7845633578675155,
      "grad_norm": 11.355697631835938,
      "learning_rate": 1.439936356404137e-06,
      "loss": 1.4048,
      "step": 7000
    },
    {
      "epoch": 2.824348518002785,
      "grad_norm": 6.308656215667725,
      "learning_rate": 1.1747547069742774e-06,
      "loss": 1.3854,
      "step": 7100
    },
    {
      "epoch": 2.8641336781380544,
      "grad_norm": 10.731643676757812,
      "learning_rate": 9.09573057544418e-07,
      "loss": 1.3387,
      "step": 7200
    },
    {
      "epoch": 2.903918838273324,
      "grad_norm": 23.638538360595703,
      "learning_rate": 6.443914081145585e-07,
      "loss": 1.3169,
      "step": 7300
    },
    {
      "epoch": 2.9437039984085938,
      "grad_norm": 15.818941116333008,
      "learning_rate": 3.7920975868469907e-07,
      "loss": 1.3046,
      "step": 7400
    },
    {
      "epoch": 2.983489158543863,
      "grad_norm": 5.105081558227539,
      "learning_rate": 1.1402810925483957e-07,
      "loss": 1.3784,
      "step": 7500
    }
  ],
  "logging_steps": 100,
  "max_steps": 7542,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.308585349768806e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
