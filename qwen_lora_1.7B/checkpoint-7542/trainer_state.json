{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 7542,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.039785160135269546,
      "grad_norm": 4.57900857925415,
      "learning_rate": 1.973747016706444e-05,
      "loss": 4.6084,
      "step": 100
    },
    {
      "epoch": 0.07957032027053909,
      "grad_norm": 2.5522830486297607,
      "learning_rate": 1.947228851763458e-05,
      "loss": 2.091,
      "step": 200
    },
    {
      "epoch": 0.11935548040580864,
      "grad_norm": 5.779054164886475,
      "learning_rate": 1.920710686820472e-05,
      "loss": 1.9141,
      "step": 300
    },
    {
      "epoch": 0.15914064054107818,
      "grad_norm": 2.5276455879211426,
      "learning_rate": 1.8941925218774862e-05,
      "loss": 1.9166,
      "step": 400
    },
    {
      "epoch": 0.1989258006763477,
      "grad_norm": 2.535309076309204,
      "learning_rate": 1.8676743569345004e-05,
      "loss": 1.8605,
      "step": 500
    },
    {
      "epoch": 0.23871096081161727,
      "grad_norm": 5.227360248565674,
      "learning_rate": 1.8411561919915143e-05,
      "loss": 1.8389,
      "step": 600
    },
    {
      "epoch": 0.2784961209468868,
      "grad_norm": 5.785388946533203,
      "learning_rate": 1.8146380270485286e-05,
      "loss": 1.8199,
      "step": 700
    },
    {
      "epoch": 0.31828128108215636,
      "grad_norm": 4.90894079208374,
      "learning_rate": 1.7881198621055425e-05,
      "loss": 1.7337,
      "step": 800
    },
    {
      "epoch": 0.3580664412174259,
      "grad_norm": 8.38969612121582,
      "learning_rate": 1.7616016971625564e-05,
      "loss": 1.7512,
      "step": 900
    },
    {
      "epoch": 0.3978516013526954,
      "grad_norm": 2.9395127296447754,
      "learning_rate": 1.7350835322195706e-05,
      "loss": 1.7419,
      "step": 1000
    },
    {
      "epoch": 0.437636761487965,
      "grad_norm": 3.4922049045562744,
      "learning_rate": 1.7085653672765845e-05,
      "loss": 1.7185,
      "step": 1100
    },
    {
      "epoch": 0.47742192162323455,
      "grad_norm": 5.006591796875,
      "learning_rate": 1.6820472023335987e-05,
      "loss": 1.6929,
      "step": 1200
    },
    {
      "epoch": 0.517207081758504,
      "grad_norm": 5.1346435546875,
      "learning_rate": 1.6555290373906126e-05,
      "loss": 1.6078,
      "step": 1300
    },
    {
      "epoch": 0.5569922418937736,
      "grad_norm": 3.4666781425476074,
      "learning_rate": 1.629010872447627e-05,
      "loss": 1.6929,
      "step": 1400
    },
    {
      "epoch": 0.5967774020290432,
      "grad_norm": 7.492171287536621,
      "learning_rate": 1.6024927075046408e-05,
      "loss": 1.6705,
      "step": 1500
    },
    {
      "epoch": 0.6365625621643127,
      "grad_norm": 8.099183082580566,
      "learning_rate": 1.5759745425616547e-05,
      "loss": 1.626,
      "step": 1600
    },
    {
      "epoch": 0.6763477222995823,
      "grad_norm": 6.07651424407959,
      "learning_rate": 1.549456377618669e-05,
      "loss": 1.649,
      "step": 1700
    },
    {
      "epoch": 0.7161328824348518,
      "grad_norm": 4.324130058288574,
      "learning_rate": 1.5229382126756828e-05,
      "loss": 1.6166,
      "step": 1800
    },
    {
      "epoch": 0.7559180425701213,
      "grad_norm": 7.96085786819458,
      "learning_rate": 1.496420047732697e-05,
      "loss": 1.6294,
      "step": 1900
    },
    {
      "epoch": 0.7957032027053909,
      "grad_norm": 5.3274245262146,
      "learning_rate": 1.4699018827897111e-05,
      "loss": 1.6129,
      "step": 2000
    },
    {
      "epoch": 0.8354883628406604,
      "grad_norm": 6.785465240478516,
      "learning_rate": 1.4433837178467252e-05,
      "loss": 1.5626,
      "step": 2100
    },
    {
      "epoch": 0.87527352297593,
      "grad_norm": 5.540851593017578,
      "learning_rate": 1.4168655529037391e-05,
      "loss": 1.6125,
      "step": 2200
    },
    {
      "epoch": 0.9150586831111995,
      "grad_norm": 4.884954452514648,
      "learning_rate": 1.3903473879607532e-05,
      "loss": 1.5661,
      "step": 2300
    },
    {
      "epoch": 0.9548438432464691,
      "grad_norm": 5.575817108154297,
      "learning_rate": 1.3638292230177672e-05,
      "loss": 1.5442,
      "step": 2400
    },
    {
      "epoch": 0.9946290033817387,
      "grad_norm": 5.65724515914917,
      "learning_rate": 1.3373110580747813e-05,
      "loss": 1.5742,
      "step": 2500
    },
    {
      "epoch": 1.0342152377163318,
      "grad_norm": 3.4693281650543213,
      "learning_rate": 1.3107928931317955e-05,
      "loss": 1.5848,
      "step": 2600
    },
    {
      "epoch": 1.0740003978516013,
      "grad_norm": 4.6591997146606445,
      "learning_rate": 1.2842747281888094e-05,
      "loss": 1.5855,
      "step": 2700
    },
    {
      "epoch": 1.113785557986871,
      "grad_norm": 10.435140609741211,
      "learning_rate": 1.2577565632458235e-05,
      "loss": 1.5007,
      "step": 2800
    },
    {
      "epoch": 1.1535707181221404,
      "grad_norm": 7.402124404907227,
      "learning_rate": 1.2312383983028376e-05,
      "loss": 1.5638,
      "step": 2900
    },
    {
      "epoch": 1.19335587825741,
      "grad_norm": 7.056375026702881,
      "learning_rate": 1.2047202333598516e-05,
      "loss": 1.4903,
      "step": 3000
    },
    {
      "epoch": 1.2331410383926795,
      "grad_norm": 11.05093765258789,
      "learning_rate": 1.1782020684168655e-05,
      "loss": 1.5222,
      "step": 3100
    },
    {
      "epoch": 1.2729261985279492,
      "grad_norm": 16.58540916442871,
      "learning_rate": 1.1516839034738796e-05,
      "loss": 1.5119,
      "step": 3200
    },
    {
      "epoch": 1.3127113586632186,
      "grad_norm": 6.367829322814941,
      "learning_rate": 1.1251657385308938e-05,
      "loss": 1.5005,
      "step": 3300
    },
    {
      "epoch": 1.352496518798488,
      "grad_norm": 7.466841220855713,
      "learning_rate": 1.0986475735879079e-05,
      "loss": 1.4899,
      "step": 3400
    },
    {
      "epoch": 1.3922816789337578,
      "grad_norm": 10.758469581604004,
      "learning_rate": 1.0721294086449218e-05,
      "loss": 1.4527,
      "step": 3500
    },
    {
      "epoch": 1.4320668390690272,
      "grad_norm": 5.637613296508789,
      "learning_rate": 1.0456112437019359e-05,
      "loss": 1.4736,
      "step": 3600
    },
    {
      "epoch": 1.4718519992042969,
      "grad_norm": 5.079667091369629,
      "learning_rate": 1.01909307875895e-05,
      "loss": 1.529,
      "step": 3700
    },
    {
      "epoch": 1.5116371593395663,
      "grad_norm": 7.523970603942871,
      "learning_rate": 9.92574913815964e-06,
      "loss": 1.4819,
      "step": 3800
    },
    {
      "epoch": 1.551422319474836,
      "grad_norm": 11.708617210388184,
      "learning_rate": 9.66056748872978e-06,
      "loss": 1.5061,
      "step": 3900
    },
    {
      "epoch": 1.5912074796101054,
      "grad_norm": 8.77865982055664,
      "learning_rate": 9.395385839299922e-06,
      "loss": 1.4538,
      "step": 4000
    },
    {
      "epoch": 1.630992639745375,
      "grad_norm": 7.134002208709717,
      "learning_rate": 9.130204189870062e-06,
      "loss": 1.4143,
      "step": 4100
    },
    {
      "epoch": 1.6707777998806446,
      "grad_norm": 7.317266464233398,
      "learning_rate": 8.865022540440203e-06,
      "loss": 1.4669,
      "step": 4200
    },
    {
      "epoch": 1.710562960015914,
      "grad_norm": 11.754539489746094,
      "learning_rate": 8.599840891010342e-06,
      "loss": 1.4298,
      "step": 4300
    },
    {
      "epoch": 1.7503481201511835,
      "grad_norm": 10.731132507324219,
      "learning_rate": 8.334659241580483e-06,
      "loss": 1.4536,
      "step": 4400
    },
    {
      "epoch": 1.7901332802864531,
      "grad_norm": 18.811553955078125,
      "learning_rate": 8.069477592150625e-06,
      "loss": 1.4601,
      "step": 4500
    },
    {
      "epoch": 1.8299184404217228,
      "grad_norm": 10.97275447845459,
      "learning_rate": 7.804295942720764e-06,
      "loss": 1.5219,
      "step": 4600
    },
    {
      "epoch": 1.8697036005569923,
      "grad_norm": 17.055654525756836,
      "learning_rate": 7.539114293290905e-06,
      "loss": 1.3876,
      "step": 4700
    },
    {
      "epoch": 1.9094887606922617,
      "grad_norm": 11.487144470214844,
      "learning_rate": 7.273932643861046e-06,
      "loss": 1.4378,
      "step": 4800
    },
    {
      "epoch": 1.9492739208275314,
      "grad_norm": 3.998866319656372,
      "learning_rate": 7.008750994431186e-06,
      "loss": 1.4161,
      "step": 4900
    },
    {
      "epoch": 1.989059080962801,
      "grad_norm": 10.169083595275879,
      "learning_rate": 6.743569345001326e-06,
      "loss": 1.4067,
      "step": 5000
    },
    {
      "epoch": 2.028645315297394,
      "grad_norm": 11.045276641845703,
      "learning_rate": 6.478387695571467e-06,
      "loss": 1.394,
      "step": 5100
    },
    {
      "epoch": 2.0684304754326637,
      "grad_norm": 6.610513210296631,
      "learning_rate": 6.213206046141608e-06,
      "loss": 1.433,
      "step": 5200
    },
    {
      "epoch": 2.1082156355679333,
      "grad_norm": 6.2396674156188965,
      "learning_rate": 5.948024396711748e-06,
      "loss": 1.3903,
      "step": 5300
    },
    {
      "epoch": 2.1480007957032026,
      "grad_norm": 5.642055034637451,
      "learning_rate": 5.6828427472818885e-06,
      "loss": 1.442,
      "step": 5400
    },
    {
      "epoch": 2.1877859558384722,
      "grad_norm": 22.139171600341797,
      "learning_rate": 5.417661097852029e-06,
      "loss": 1.3863,
      "step": 5500
    },
    {
      "epoch": 2.227571115973742,
      "grad_norm": 29.81449317932129,
      "learning_rate": 5.15247944842217e-06,
      "loss": 1.4701,
      "step": 5600
    },
    {
      "epoch": 2.2673562761090116,
      "grad_norm": 14.298849105834961,
      "learning_rate": 4.887297798992311e-06,
      "loss": 1.3889,
      "step": 5700
    },
    {
      "epoch": 2.307141436244281,
      "grad_norm": 8.903072357177734,
      "learning_rate": 4.62211614956245e-06,
      "loss": 1.3864,
      "step": 5800
    },
    {
      "epoch": 2.3469265963795505,
      "grad_norm": 7.292816638946533,
      "learning_rate": 4.356934500132591e-06,
      "loss": 1.3963,
      "step": 5900
    },
    {
      "epoch": 2.38671175651482,
      "grad_norm": 7.396125316619873,
      "learning_rate": 4.091752850702732e-06,
      "loss": 1.3183,
      "step": 6000
    },
    {
      "epoch": 2.4264969166500894,
      "grad_norm": 9.012255668640137,
      "learning_rate": 3.8265712012728725e-06,
      "loss": 1.3711,
      "step": 6100
    },
    {
      "epoch": 2.466282076785359,
      "grad_norm": 8.57633113861084,
      "learning_rate": 3.5613895518430123e-06,
      "loss": 1.2625,
      "step": 6200
    },
    {
      "epoch": 2.5060672369206287,
      "grad_norm": 4.586246490478516,
      "learning_rate": 3.2962079024131534e-06,
      "loss": 1.3291,
      "step": 6300
    },
    {
      "epoch": 2.5458523970558984,
      "grad_norm": 7.578850746154785,
      "learning_rate": 3.031026252983294e-06,
      "loss": 1.4015,
      "step": 6400
    },
    {
      "epoch": 2.5856375571911676,
      "grad_norm": 13.111873626708984,
      "learning_rate": 2.7658446035534344e-06,
      "loss": 1.3963,
      "step": 6500
    },
    {
      "epoch": 2.6254227173264373,
      "grad_norm": 6.767800331115723,
      "learning_rate": 2.500662954123575e-06,
      "loss": 1.3673,
      "step": 6600
    },
    {
      "epoch": 2.6652078774617065,
      "grad_norm": NaN,
      "learning_rate": 2.2354813046937153e-06,
      "loss": 1.4267,
      "step": 6700
    },
    {
      "epoch": 2.704993037596976,
      "grad_norm": 24.238515853881836,
      "learning_rate": 1.970299655263856e-06,
      "loss": 1.364,
      "step": 6800
    },
    {
      "epoch": 2.744778197732246,
      "grad_norm": 23.483211517333984,
      "learning_rate": 1.7051180058339964e-06,
      "loss": 1.4349,
      "step": 6900
    },
    {
      "epoch": 2.7845633578675155,
      "grad_norm": 12.56990909576416,
      "learning_rate": 1.439936356404137e-06,
      "loss": 1.4221,
      "step": 7000
    },
    {
      "epoch": 2.824348518002785,
      "grad_norm": 4.93007755279541,
      "learning_rate": 1.1747547069742774e-06,
      "loss": 1.4123,
      "step": 7100
    },
    {
      "epoch": 2.8641336781380544,
      "grad_norm": 11.296696662902832,
      "learning_rate": 9.09573057544418e-07,
      "loss": 1.3771,
      "step": 7200
    },
    {
      "epoch": 2.903918838273324,
      "grad_norm": 18.9238338470459,
      "learning_rate": 6.443914081145585e-07,
      "loss": 1.3328,
      "step": 7300
    },
    {
      "epoch": 2.9437039984085938,
      "grad_norm": 13.529620170593262,
      "learning_rate": 3.7920975868469907e-07,
      "loss": 1.3326,
      "step": 7400
    },
    {
      "epoch": 2.983489158543863,
      "grad_norm": 5.8182597160339355,
      "learning_rate": 1.1402810925483957e-07,
      "loss": 1.4068,
      "step": 7500
    }
  ],
  "logging_steps": 100,
  "max_steps": 7542,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.973154239029944e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
